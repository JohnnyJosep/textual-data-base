{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploració de les Dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repositori a GitHub: https://github.com/JohnnyJosep/textual-data-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  \n",
    "import re\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.corpus.reader.wordnet import WordNetCorpusReader\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregan les dades i veim la forma que tenen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Señorías, antes de nada quiero recordar a quienes ocupan las tribunas de invitados que no pueden hacer manifestaciones de ningún tipo mientras dura la sesión. Se abre la sesión con el único punto en el orden del día, como ustedes saben, relativo al debate sobre la investidura del candidato a la Presidencia del Gobierno. Para ello, por la secretaria primera de la Cámara se va a proceder a la lectura de la propuesta de candidato a la Presidencia del Gobierno.\n",
      "PRESIDENTE\n",
      "DEBATE SOBRE LA INVESTIDURA DEL CANDIDATO A LA PRESIDENCIA DEL GOBIERNO. \n",
      "./data/diaries-txts/DSCD-11-PL-002.txt\n"
     ]
    }
   ],
   "source": [
    "with open('./data/data.pickle', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data[0].text)\n",
    "print(data[0].meta['speacker'])\n",
    "print(data[0].meta['debate'])\n",
    "print(data[0].meta['path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Señorías, antes de nada quiero recordar a quienes ocupan las tribunas de invitados que no pueden hacer manifestaciones de ningún tipo mientras dura la sesión. Se abre la sesión con el único punto en el orden del día, como ustedes saben, relativo al debate sobre la investidura del candidato a la Presidencia del Gobierno. Para ello, por la secretaria primera de la Cámara se va a proceder a la lectura de la propuesta de candidato a la Presidencia del Gobierno.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data[0].text\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerem ara el text com a unitats d'informació més petites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separem el texte per oracions. *Per fer-ho en espanyol carregan la llibreria previament.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_sentence_tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Señorías, antes de nada quiero recordar a quienes ocupan las tribunas de invitados que no pueden hacer manifestaciones de ningún tipo mientras dura la sesión.',\n",
       " 'Se abre la sesión con el único punto en el orden del día, como ustedes saben, relativo al debate sobre la investidura del candidato a la Presidencia del Gobierno.',\n",
       " 'Para ello, por la secretaria primera de la Cámara se va a proceder a la lectura de la propuesta de candidato a la Presidencia del Gobierno.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = spanish_sentence_tokenizer.tokenize(text)\n",
    "sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas de texte a paraules. Cal notar que no s'eliminen els signes de puntuació (més endavant seràn útils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Señorías',\n",
       " ',',\n",
       " 'antes',\n",
       " 'de',\n",
       " 'nada',\n",
       " 'quiero',\n",
       " 'recordar',\n",
       " 'a',\n",
       " 'quienes',\n",
       " 'ocupan',\n",
       " 'las',\n",
       " 'tribunas',\n",
       " 'de',\n",
       " 'invitados',\n",
       " 'que',\n",
       " 'no',\n",
       " 'pueden',\n",
       " 'hacer',\n",
       " 'manifestaciones',\n",
       " 'de',\n",
       " 'ningún',\n",
       " 'tipo',\n",
       " 'mientras',\n",
       " 'dura',\n",
       " 'la',\n",
       " 'sesión',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(sentences[0])\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del vector de paraules anterior anam a filtrar aquelles paraulres que no tenen un significat substancial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Señorías',\n",
       " ',',\n",
       " 'quiero',\n",
       " 'recordar',\n",
       " 'ocupan',\n",
       " 'tribunas',\n",
       " 'invitados',\n",
       " 'pueden',\n",
       " 'hacer',\n",
       " 'manifestaciones',\n",
       " 'ningún',\n",
       " 'tipo',\n",
       " 'mientras',\n",
       " 'dura',\n",
       " 'sesión',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_without_stopwords = [t for t in words if t not in spanish_stopwords]\n",
    "tokens_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del vector anterior anam a extreure l'arrel de cada paraula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['señor',\n",
       " ',',\n",
       " 'quier',\n",
       " 'record',\n",
       " 'ocup',\n",
       " 'tribun',\n",
       " 'invit',\n",
       " 'pued',\n",
       " 'hac',\n",
       " 'manifest',\n",
       " 'ningun',\n",
       " 'tip',\n",
       " 'mientr',\n",
       " 'dur',\n",
       " 'sesion',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_stemming = [spanish_stemmer.stem(t) for t in tokens_without_stopwords]\n",
    "tokens_stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alumbr\n",
      "alumbr\n"
     ]
    }
   ],
   "source": [
    "print(spanish_stemmer.stem('alumbre'))\n",
    "print(spanish_stemmer.stem('alumbrado'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cal notar que aquesta normalitació pot tenir una tasa d'error elevada. Ja que per a paraules que no tene el mateix significat pero el mateix comançament o arrel com el cas anterior (alumbre vs alumbrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fent use de http://nlp.lsi.upc.edu/freeling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_path = './data/chunks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(data)):\n",
    "    chunk = data[i]\n",
    "    chunk_plain_path = f'{chunks_path}/{i:05d}.txt'\n",
    "    with open(chunk_plain_path, 'w', encoding = 'utf-8') as file:\n",
    "        file.write(chunk.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciar servidor \n",
    "\n",
    "`analyze.bat -f freeling_es.cfg --server --port 50005 &`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar comando en PowerShell \n",
    "\n",
    "`Get-ChildItem -Filter *.txt | ForEach-Object { if (-not (Test-Path \"$($_.FullName).mrf\" -PathType leaf)) { cmd.exe /c \"analyzer_client.exe 50005 < $($_.FullName) > $($_.FullName).mrf\" } }`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formato mrf\n",
    "Es una Tupla < word, lema, PoS tag, probability >\n",
    "\n",
    "Leyenda PoS Tag: https://freeling-user-manual.readthedocs.io/en/v4.2/tagsets/tagset-es/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracias, señor Martínez. Tiene la palabra la señora Oramas, también por cinco minutos.\n",
      "Gracias gracia NCFP000 1\n",
      ", , Fc 1\n",
      "señor señor NCMS000 0.957935\n",
      "Martínez martínez NP00SP0 1\n",
      ". . Fp 1\n",
      "\n",
      "Tiene tener VMIP3S0 1\n",
      "la el DA0FS0 0.98926\n",
      "palabra palabra NCFS000 1\n",
      "la el DA0FS0 0.98926\n",
      "señora señor NCFS000 0.99569\n",
      "Oramas oramas NP00SP0 1\n",
      ", , Fc 1\n",
      "también también RG 1\n",
      "por por SP 1\n",
      "cinco_minutos TM_min:5 Zu 1\n",
      ". . Fp 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_morfo(i):\n",
    "    chunk_morfo_path = f'{chunks_path}/{i:05d}.txt.mrf'\n",
    "    with open(chunk_morfo_path, 'r', encoding = 'utf-8') as file:\n",
    "        return file.read()\n",
    "    \n",
    "print(data[41].text)\n",
    "print(get_morfo(41))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cálido', 'cálido', 'cálido', 'amable', 'cálido', 'afectuoso', 'cálido']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wncr = WordNetCorpusReader('./wordnet_spa', None)\n",
    "\n",
    "word = 'cálido'\n",
    "\n",
    "[ss.name().split('.')[0] for ss in wncr.synsets(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abrasador',\n",
       " 'acogedor',\n",
       " 'afectivo',\n",
       " 'afectuoso',\n",
       " 'amigable',\n",
       " 'ardiente',\n",
       " 'ardoroso',\n",
       " 'caliente',\n",
       " 'calinoso',\n",
       " 'caluroso',\n",
       " 'candente',\n",
       " 'canicular',\n",
       " 'cordial',\n",
       " 'entrañable',\n",
       " 'moderado',\n",
       " 'sofocante',\n",
       " 'suave',\n",
       " 'templado',\n",
       " 'tórrido',\n",
       " 'tropical']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = urllib.request.urlopen(f'https://educalingo.com/en/dic-es/{unidecode.unidecode(word)}').read()\n",
    "synonyms = [s.text for s in soup(data, 'html.parser').select('.contenido_sinonimos_antonimos0')[0].select('a')]\n",
    "synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subeqüències de *n* paraules sobre el texte donat com unitats d'informació. *(Exemple fàcil d'entendre de l'anglés: 'ice cream')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'señorías, antes de nada quiero recordar a quienes ocupan las tribunas de invitados que no pueden hacer manifestaciones de ningún tipo mientras dura la sesión.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = \" \".join([d.text.lower() for d in data])\n",
    "full_sentences = spanish_sentence_tokenizer.tokenize(full_text)\n",
    "full_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('señorías', ',', 'antes', 'de', 'nada'),\n",
       " (',', 'antes', 'de', 'nada', 'quiero'),\n",
       " ('antes', 'de', 'nada', 'quiero', 'recordar'),\n",
       " ('de', 'nada', 'quiero', 'recordar', 'a'),\n",
       " ('nada', 'quiero', 'recordar', 'a', 'quienes'),\n",
       " ('quiero', 'recordar', 'a', 'quienes', 'ocupan'),\n",
       " ('recordar', 'a', 'quienes', 'ocupan', 'las'),\n",
       " ('a', 'quienes', 'ocupan', 'las', 'tribunas'),\n",
       " ('quienes', 'ocupan', 'las', 'tribunas', 'de'),\n",
       " ('ocupan', 'las', 'tribunas', 'de', 'invitados'),\n",
       " ('las', 'tribunas', 'de', 'invitados', 'que'),\n",
       " ('tribunas', 'de', 'invitados', 'que', 'no'),\n",
       " ('de', 'invitados', 'que', 'no', 'pueden'),\n",
       " ('invitados', 'que', 'no', 'pueden', 'hacer'),\n",
       " ('que', 'no', 'pueden', 'hacer', 'manifestaciones'),\n",
       " ('no', 'pueden', 'hacer', 'manifestaciones', 'de'),\n",
       " ('pueden', 'hacer', 'manifestaciones', 'de', 'ningún'),\n",
       " ('hacer', 'manifestaciones', 'de', 'ningún', 'tipo'),\n",
       " ('manifestaciones', 'de', 'ningún', 'tipo', 'mientras'),\n",
       " ('de', 'ningún', 'tipo', 'mientras', 'dura'),\n",
       " ('ningún', 'tipo', 'mientras', 'dura', 'la'),\n",
       " ('tipo', 'mientras', 'dura', 'la', 'sesión'),\n",
       " ('mientras', 'dura', 'la', 'sesión', '.')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_sentence_0 = word_tokenize(full_sentences[0])\n",
    "five_grams = list(ngrams(words_sentence_0, 5))\n",
    "five_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar aquí la presencia de signes de puntuació.\n",
    "\n",
    "Considerant que aquets, per la seva naturalesa, separan unitats d'informació anem a filtrar els ngrames obtinguts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antes', 'de', 'nada', 'quiero', 'recordar'),\n",
       " ('de', 'nada', 'quiero', 'recordar', 'a'),\n",
       " ('nada', 'quiero', 'recordar', 'a', 'quienes'),\n",
       " ('quiero', 'recordar', 'a', 'quienes', 'ocupan'),\n",
       " ('recordar', 'a', 'quienes', 'ocupan', 'las'),\n",
       " ('a', 'quienes', 'ocupan', 'las', 'tribunas'),\n",
       " ('quienes', 'ocupan', 'las', 'tribunas', 'de'),\n",
       " ('ocupan', 'las', 'tribunas', 'de', 'invitados'),\n",
       " ('las', 'tribunas', 'de', 'invitados', 'que'),\n",
       " ('tribunas', 'de', 'invitados', 'que', 'no'),\n",
       " ('de', 'invitados', 'que', 'no', 'pueden'),\n",
       " ('invitados', 'que', 'no', 'pueden', 'hacer'),\n",
       " ('que', 'no', 'pueden', 'hacer', 'manifestaciones'),\n",
       " ('no', 'pueden', 'hacer', 'manifestaciones', 'de'),\n",
       " ('pueden', 'hacer', 'manifestaciones', 'de', 'ningún'),\n",
       " ('hacer', 'manifestaciones', 'de', 'ningún', 'tipo'),\n",
       " ('manifestaciones', 'de', 'ningún', 'tipo', 'mientras'),\n",
       " ('de', 'ningún', 'tipo', 'mientras', 'dura'),\n",
       " ('ningún', 'tipo', 'mientras', 'dura', 'la'),\n",
       " ('tipo', 'mientras', 'dura', 'la', 'sesión')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r'[.,\\/#!$%\\^&\\*;:{}=\\-_`~()”“\"…]')\n",
    "five_ngrams_without_punctuation = [n5 for n5 in five_grams if pattern.search(n5[0]) == None and pattern.search(n5[1]) == None and pattern.search(n5[2]) == None and pattern.search(n5[3]) == None and pattern.search(n5[4]) == None]\n",
    "five_ngrams_without_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antes', 'de', 'nada', 'quiero', 'recordar'),\n",
       " ('de', 'nada', 'quiero', 'recordar', 'a'),\n",
       " ('nada', 'quiero', 'recordar', 'a', 'quienes'),\n",
       " ('quiero', 'recordar', 'a', 'quienes', 'ocupan'),\n",
       " ('recordar', 'a', 'quienes', 'ocupan', 'las'),\n",
       " ('a', 'quienes', 'ocupan', 'las', 'tribunas'),\n",
       " ('quienes', 'ocupan', 'las', 'tribunas', 'de'),\n",
       " ('ocupan', 'las', 'tribunas', 'de', 'invitados'),\n",
       " ('las', 'tribunas', 'de', 'invitados', 'que'),\n",
       " ('tribunas', 'de', 'invitados', 'que', 'no'),\n",
       " ('de', 'invitados', 'que', 'no', 'pueden'),\n",
       " ('invitados', 'que', 'no', 'pueden', 'hacer'),\n",
       " ('que', 'no', 'pueden', 'hacer', 'manifestaciones'),\n",
       " ('no', 'pueden', 'hacer', 'manifestaciones', 'de'),\n",
       " ('pueden', 'hacer', 'manifestaciones', 'de', 'ningún'),\n",
       " ('hacer', 'manifestaciones', 'de', 'ningún', 'tipo'),\n",
       " ('manifestaciones', 'de', 'ningún', 'tipo', 'mientras'),\n",
       " ('de', 'ningún', 'tipo', 'mientras', 'dura'),\n",
       " ('ningún', 'tipo', 'mientras', 'dura', 'la'),\n",
       " ('tipo', 'mientras', 'dura', 'la', 'sesión')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fiveGrams(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    five_grams = list(ngrams(words, 5))\n",
    "    five_ngrams_without_punctuation = [n5 for n5 in five_grams if pattern.search(n5[0]) == None and pattern.search(n5[1]) == None and pattern.search(n5[2]) == None and pattern.search(n5[3]) == None and pattern.search(n5[4]) == None]\n",
    "    return five_ngrams_without_punctuation\n",
    "\n",
    "fiveGrams(full_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerem ara els tokens i la seva freqüència"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Señorías': 1,\n",
       "         ',': 1,\n",
       "         'quiero': 1,\n",
       "         'recordar': 1,\n",
       "         'ocupan': 1,\n",
       "         'tribunas': 1,\n",
       "         'invitados': 1,\n",
       "         'pueden': 1,\n",
       "         'hacer': 1,\n",
       "         'manifestaciones': 1,\n",
       "         'ningún': 1,\n",
       "         'tipo': 1,\n",
       "         'mientras': 1,\n",
       "         'dura': 1,\n",
       "         'sesión': 1,\n",
       "         '.': 1})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = Counter(tokens_without_stopwords)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'[.\\?\\¿\\!\\¡,\\/#!$%\\^&\\*;:{}=\\-_`~()”“\"…]')\n",
    "full_text = \" \".join([pattern.sub('', d.text.lower()) for d in data])\n",
    "full_words = word_tokenize(full_text)\n",
    "full_tokens = [t for t in full_words if t not in spanish_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La següent llista conté les 20 paraules més utilitzades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('señor', 32573),\n",
       " ('gobierno', 30272),\n",
       " ('gracias', 28093),\n",
       " ('ley', 25222),\n",
       " ('ustedes', 24460),\n",
       " ('grupo', 24078),\n",
       " ('si', 22332),\n",
       " ('muchas', 21226),\n",
       " ('señorías', 20368),\n",
       " ('señora', 18742),\n",
       " ('partido', 17631),\n",
       " ('españa', 17193),\n",
       " ('hoy', 16720),\n",
       " ('parlamentario', 16055),\n",
       " ('aplausos', 15387),\n",
       " ('usted', 14743),\n",
       " ('ser', 14534),\n",
       " ('popular', 13801),\n",
       " ('país', 13297),\n",
       " ('aquí', 12206)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_bag_of_words = Counter(full_tokens)\n",
    "full_bag_of_words.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72586"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = len(full_bag_of_words)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44749893527868223"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_bag_of_words['señor'] / unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2001538694033439"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_bag_of_words['estado'] / unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aleshores, podriem pensar que les paraules més utilitzades podrien ser les paraules que pel contexte d'informació no aporten informació rellevant al tema del texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['señorías',\n",
       " 'hacer',\n",
       " 'día',\n",
       " 'ustedes',\n",
       " 'gobierno',\n",
       " 'cámara',\n",
       " 'va',\n",
       " 'gracias',\n",
       " 'acuerdo',\n",
       " 'señor',\n",
       " 'bien',\n",
       " 'palabra',\n",
       " 'aplausos',\n",
       " 'aquí',\n",
       " 'política',\n",
       " 'país',\n",
       " 'ciudadanos',\n",
       " 'hoy',\n",
       " 'hecho',\n",
       " 'sido',\n",
       " 'ser',\n",
       " 'vez',\n",
       " 'partido',\n",
       " 'grupo',\n",
       " 'parlamentario',\n",
       " 'socialista',\n",
       " 'así',\n",
       " 'si',\n",
       " 'sino',\n",
       " 'solo',\n",
       " 'ahora',\n",
       " 'hace',\n",
       " 'dos',\n",
       " 'sistema',\n",
       " 'años',\n",
       " 'parte',\n",
       " 'millones',\n",
       " 'popular',\n",
       " 'puede',\n",
       " 'vamos',\n",
       " 'españa',\n",
       " 'social',\n",
       " 'personas',\n",
       " 'ley',\n",
       " 'además',\n",
       " 'favor',\n",
       " 'decir',\n",
       " 'derechos',\n",
       " 'medidas',\n",
       " 'todas',\n",
       " 'caso',\n",
       " 'usted',\n",
       " 'año',\n",
       " 'derecho',\n",
       " 'muchas',\n",
       " 'real',\n",
       " 'señora',\n",
       " 'presidenta']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_stopwords = [f for f in full_bag_of_words if full_bag_of_words[f] / unique_words > 0.1]\n",
    "more_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seguridad', 7225),\n",
       " ('lugar', 7223),\n",
       " ('diputados', 7098),\n",
       " ('presidente', 6960),\n",
       " ('trabajo', 6946),\n",
       " ('mismo', 6929),\n",
       " ('podemos', 6821),\n",
       " ('empleo', 6816),\n",
       " ('situación', 6732),\n",
       " ('dicho', 6673),\n",
       " ('españoles', 6611),\n",
       " ('menos', 6564),\n",
       " ('momento', 6521),\n",
       " ('tener', 6513),\n",
       " ('proposición', 6477),\n",
       " ('comisión', 6418),\n",
       " ('poder', 6363),\n",
       " ('ministro', 6289),\n",
       " ('cada', 6281),\n",
       " ('tiempo', 6249)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [t.lower() for t in full_tokens if t not in more_stopwords]\n",
    "bag_of_words = Counter(tokens)\n",
    "bag_of_words.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0996166997573351"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words['seguridad'] / len(bag_of_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
